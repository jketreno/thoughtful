# Choose either openai or claude
LLM_MODE=openai
# LLM_MODE=claude

# If using Claude, set ANTHROPIC_API_KEY and MODEL_NAME:
#MODEL_NAME=claude-3-5-haiku-latest
#ANTHROPIC_API_KEY=your_anthropic_api_key

# If using OpenAI, set OPENAI_API_KEY and MODEL_NAME:
MODEL_NAME=qwen2.5:7b
#OPENAI_API_KEY=your_openai_key

# If using self hosted Ollama, you don't need the OPENAI_API_KEY,
# just set OPENAI_URL to your Ollama server URL. I run Ollama
# out of another container on my local machine on Linux,
# which means host.docker.internal doesn't exist as a DNS
# record (it does on Windows and OSX).
#OPENAI_URL=http://host.docker.internal:11434/v1
OPENAI_URL=http://172.17.0.1:11434/v1
